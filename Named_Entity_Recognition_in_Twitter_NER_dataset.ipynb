{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfoxzOhV_V1c"
      },
      "source": [
        "# Named Entity Recognition in Twitter-NER dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0ebzdK__V1f",
        "outputId": "19238651-b809-4ba7-a15f-be28ab9531bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-crfsuite\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 33.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 153 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 184 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 225 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 235 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 245 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 256 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 266 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 276 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 286 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 296 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 307 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 317 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 327 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 337 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 348 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 358 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 368 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 378 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 399 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 409 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 430 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 440 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 450 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 460 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 471 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 481 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 491 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 501 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 512 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 522 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 532 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 542 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 552 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 563 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 573 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 583 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 593 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 604 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 614 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 624 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 634 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 645 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 655 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 665 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 675 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 686 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 696 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 706 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 716 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 727 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 737 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 747 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 757 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 768 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 778 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 788 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 798 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 808 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 819 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 829 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 839 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 849 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 860 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 870 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 880 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 890 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 901 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 911 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 921 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 931 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 942 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 952 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 962 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 965 kB 25.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=4ff37945381f86325e65b28d2728523cf6c709c3387ac7ee004ad1dd8d82d6c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-crfsuite\n",
        "!pip install seqeval\n",
        "from itertools import chain\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn\n",
        "import pycrfsuite\n",
        "from nltk.corpus.reader import ConllChunkCorpusReader\n",
        "from seqeval.metrics import accuracy_score\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.scheme import IOB1\n",
        "import codecs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGi7LnYQ_V1i"
      },
      "source": [
        "## Reading Train/Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVbUIoKd_V1i",
        "outputId": "1d34504e-23a3-4f1b-8865-a69053e42c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2394\n"
          ]
        }
      ],
      "source": [
        "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.train\",chunk_types=\"pos\")\n",
        "train_corpus = []\n",
        "for tree in mycorpus.tagged_sents():\n",
        "    train_corpus.append(tree)\n",
        "    \n",
        "print(len(train_corpus))\n",
        "# print(train_corpus[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bpV0iNJ_V1j",
        "outputId": "26118987-6c94-44f4-c439-86bf892b227c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3850\n"
          ]
        }
      ],
      "source": [
        "mycorpus = ConllChunkCorpusReader(r\"Twitter-NER/\", r\".*\\.test\",chunk_types=\"pos\")\n",
        "test_corpus = []\n",
        "for tree in mycorpus.tagged_sents():\n",
        "    test_corpus.append(tree)\n",
        "print(len(test_corpus))\n",
        "# print(test_corpus[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35vuo9Pf_V1j"
      },
      "source": [
        "## Features\n",
        "Next, define some features. In this example we use word identity, word suffix, word shape; also, some information from nearby words is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PD0pk0Kv_V1j"
      },
      "outputs": [],
      "source": [
        "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def word2featuresTest(sent, i):\n",
        "    word = sent[i]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2featuresTest(sent):\n",
        "    return [word2featuresTest(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2_DE94t_V1k",
        "outputId": "696b2bd2-53e1-4ab9-e2e1-46e77e19becf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('RT', 'O')\n",
            "['bias', 'word.lower=rt', 'word[-3:]=RT', 'word[-2:]=RT', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'BOS', '+1:word.lower=@liltwist', '+1:word.istitle=False', '+1:word.isupper=False']\n"
          ]
        }
      ],
      "source": [
        "X_train = [sent2features(s) for s in train_corpus]\n",
        "y_train = [sent2labels(s) for s in train_corpus]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_corpus]\n",
        "y_test = [sent2labels(s) for s in test_corpus]\n",
        "\n",
        "print(train_corpus[5][0])\n",
        "print(X_train[5][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "whqtZIcg_V1l"
      },
      "outputs": [],
      "source": [
        "# 1%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLqLI6sp_V1l"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "SbH4ci4z_V1l"
      },
      "outputs": [],
      "source": [
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-4,  # coefficient for L2 penalty\n",
        "    'max_iterations': 100,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahbwDwHU_V1m"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofN6ZWqT_V1m",
        "outputId": "c81ba17c-2146-4a8b-8c63-ef816529253a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.8 s, sys: 47.1 ms, total: 11.8 s\n",
            "Wall time: 11.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer.train('twitter-ner.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rw8kKC2_V1m",
        "outputId": "3e211038-961f-41dc-85e7-1710cfd1a6eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f34c150f550>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('twitter-ner.crfsuite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uhivejT_V1n"
      },
      "source": [
        "## Obtaining Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH-a5SeM_V1n",
        "outputId": "df3f4bbf-0cdf-4e4b-ae8b-daf3b0a10c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 328 ms, sys: 4.8 ms, total: 333 ms\n",
            "Wall time: 339 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUyLfL2c_V1n"
      },
      "source": [
        "## Dumping Predictions to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mifFlR__V1n"
      },
      "outputs": [],
      "source": [
        "with codecs.open('crf.out.txt', 'w') as out_file:\n",
        "    for every_sent,pred_label in zip(test_corpus, y_pred):\n",
        "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
        "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
        "            out_file.write(\"\\n\")\n",
        "        out_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL-JaaDK_V1o"
      },
      "outputs": [],
      "source": [
        "def conllReader(filename, word_field=0, label_field=1, prediction_field=2):\n",
        "    sentences_true_labels = []\n",
        "    sentences_pred_labels = []\n",
        "    true_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    \n",
        "    with codecs.open(filename, 'r', errors='ignore', encoding='utf8') as f_in:\n",
        "        for line in f_in:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                if line.startswith('#'):\n",
        "                    continue\n",
        "                label = line.split('\\t')[label_field]\n",
        "                pred = line.split('\\t')[prediction_field]\n",
        "                true_list.append( label )\n",
        "                pred_list.append( pred )\n",
        "                \n",
        "            else:\n",
        "                if len(true_list) > 0:\n",
        "                    sentences_true_labels.append( true_list )\n",
        "                    sentences_pred_labels.append( pred_list )\n",
        "                true_list = []\n",
        "                pred_list = []\n",
        "        f_in.close()\n",
        "        \n",
        "    return sentences_true_labels, sentences_pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aT5Mln1_V1o"
      },
      "outputs": [],
      "source": [
        "true_labels, predicted_labels = conllReader(\"crf.out.txt\")\n",
        "# predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ckQqRDm_V1p",
        "outputId": "73e76814-58b6-4c05-a66f-e39deb46a0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score is\n",
            "0.25871559633027524\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     company       0.72      0.10      0.18       586\n",
            "    facility       0.49      0.29      0.36       244\n",
            "     geo-loc       0.63      0.38      0.47       768\n",
            "       movie       0.33      0.04      0.06        28\n",
            " musicartist       0.11      0.01      0.01       180\n",
            "       other       0.23      0.07      0.10       535\n",
            "      person       0.33      0.22      0.26       466\n",
            "     product       0.33      0.02      0.04       216\n",
            "  sportsteam       0.00      0.00      0.00       128\n",
            "      tvshow       0.00      0.00      0.00        24\n",
            "\n",
            "   micro avg       0.48      0.18      0.26      3175\n",
            "   macro avg       0.32      0.11      0.15      3175\n",
            "weighted avg       0.44      0.18      0.23      3175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('F1 Score is')\n",
        "print( f1_score(true_labels, predicted_labels) )\n",
        "\n",
        "print('Classification report')\n",
        "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD400nmp_V1p"
      },
      "source": [
        "## Attaching PoS Tagger-based features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qWSZdwi_V1p",
        "outputId": "74ef5533-55e2-4922-8387-b7f6c2751721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f34c11afb90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "postagger = pycrfsuite.Tagger()\n",
        "postagger.open('twitter-ner.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL1Z8ZAW_V1p"
      },
      "outputs": [],
      "source": [
        "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
        "def word2featurespos(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][2]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'postag=' + postag,\n",
        "        'postag[:2]=' + postag[:2],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][2]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            '-1:postag=' + postag1,\n",
        "            '-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][2]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            '+1:postag=' + postag1,\n",
        "            '+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def sent2featurespos(sent, postagger):\n",
        "    tagged = postagger.tag(sent2features(sent))\n",
        "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
        "    return [word2featurespos(sentNew, i) for i in range(len(sentNew))]\n",
        "\n",
        "def sent2labelspos(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokenspos(sent):\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJwQRWMp_V1q",
        "outputId": "b3e42513-1f0f-4bda-9935-ad20645ff67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('@SammieLynnsMom', 'O'), ('@tg10781', 'O'), ('they', 'O'), ('will', 'O'), ('be', 'O'), ('all', 'O'), ('done', 'O'), ('by', 'O'), ('Sunday', 'O'), ('trust', 'O'), ('me', 'O'), ('*wink*', 'O')]\n",
            "\n",
            "\n",
            "[('@SammieLynnsMom', 'O', 'O'), ('@tg10781', 'O', 'O'), ('they', 'O', 'O'), ('will', 'O', 'O'), ('be', 'O', 'O'), ('all', 'O', 'O'), ('done', 'O', 'O'), ('by', 'O', 'O'), ('Sunday', 'O', 'O'), ('trust', 'O', 'O'), ('me', 'O', 'O'), ('*wink*', 'O', 'O')]\n"
          ]
        }
      ],
      "source": [
        "for sent in train_corpus:\n",
        "    print(sent)\n",
        "    print(\"\\n\")\n",
        "    s1 = postagger.tag(sent2features(sent))\n",
        "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, s1)]\n",
        "    print(sentNew)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORD0LWzu_V1q"
      },
      "outputs": [],
      "source": [
        "X_train_pos = [sent2featurespos(s, postagger) for s in train_corpus]\n",
        "y_train_pos = [sent2labelspos(s) for s in train_corpus]\n",
        "\n",
        "X_test_pos = [sent2featurespos(s, postagger) for s in test_corpus]\n",
        "y_test_pos = [sent2labelspos(s) for s in test_corpus]\n",
        "\n",
        "# print(X_train_pos[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJg6noyj_V1q"
      },
      "outputs": [],
      "source": [
        "trainerpos = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train_pos, y_train_pos):\n",
        "    trainerpos.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "EyWBoYbs_V1q"
      },
      "outputs": [],
      "source": [
        "trainerpos.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 100,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI2v7KEg_V1r",
        "outputId": "2cb879c1-247d-49c2-9d97-c2a58571e980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.9 s, sys: 71.1 ms, total: 14 s\n",
            "Wall time: 14 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainerpos.train('twitter-ner-pos.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1kkj3_Q_V1r",
        "outputId": "614dc614-038f-492a-9671-00f7371707ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f34b6eca150>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "taggerpos = pycrfsuite.Tagger()\n",
        "taggerpos.open('twitter-ner-pos.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77gxwKX4_V1r",
        "outputId": "07f48f62-1b94-424d-8b23-dfc5e5b16552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 472 ms, sys: 2.88 ms, total: 474 ms\n",
            "Wall time: 476 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_pred_pos = [taggerpos.tag(xseq) for xseq in X_test_pos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_F9MBCFw_V1r"
      },
      "outputs": [],
      "source": [
        "with codecs.open('crf.out.pos.txt', 'w') as out_file:\n",
        "    for every_sent,pred_label in zip(test_corpus, y_pred_pos):\n",
        "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
        "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
        "            out_file.write(\"\\n\")\n",
        "        out_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcq5-V3L_V1r"
      },
      "outputs": [],
      "source": [
        "true_labels, predicted_labels = conllReader(\"crf.out.pos.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ7a5aV4_V1s",
        "outputId": "949831f0-e47d-481d-fcd3-e36e86973f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score is\n",
            "0.25929325378614043\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     company       0.72      0.10      0.18       586\n",
            "    facility       0.48      0.29      0.36       244\n",
            "     geo-loc       0.63      0.38      0.47       768\n",
            "       movie       0.33      0.04      0.06        28\n",
            " musicartist       0.11      0.01      0.01       180\n",
            "       other       0.23      0.07      0.10       535\n",
            "      person       0.33      0.22      0.27       466\n",
            "     product       0.33      0.02      0.04       216\n",
            "  sportsteam       0.00      0.00      0.00       128\n",
            "      tvshow       0.00      0.00      0.00        24\n",
            "\n",
            "   micro avg       0.48      0.18      0.26      3175\n",
            "   macro avg       0.32      0.11      0.15      3175\n",
            "weighted avg       0.44      0.18      0.24      3175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('F1 Score is')\n",
        "print( f1_score(true_labels, predicted_labels) )\n",
        "\n",
        "print('Classification report')\n",
        "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFNYW4WF_V1s"
      },
      "source": [
        "## Adding Gazatteer features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lPxw7o1_V1s"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus.reader import plaintext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPryGROQ_V1t"
      },
      "outputs": [],
      "source": [
        "personGazetteer = []\n",
        "\n",
        "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"firstname.5000\")\n",
        "person = []\n",
        "for sent in mycorpus.words():\n",
        "    person.append(sent)\n",
        "    \n",
        "mycorpus = plaintext.PlaintextCorpusReader(\"./Twitter-NER/\", \"lastname.5000\")\n",
        "for sent in mycorpus.words():\n",
        "    person.append(sent)\n",
        "\n",
        "person = [name.lower() for name in person]\n",
        "personGazetteer = set(person)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lwvKyX9d_V1t"
      },
      "outputs": [],
      "source": [
        "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
        "def word2featuresGaz(sent, i, personGaz):\n",
        "    word = sent[i][0]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def word2featuresTest(sent, i):\n",
        "    word = sent[i]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def sent2featuresGaz(sent, personGaz):\n",
        "    return [word2featuresGaz(sent, i, personGaz) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hFx7DP7_V1t"
      },
      "outputs": [],
      "source": [
        "X_train_gaz = [sent2featuresGaz(s, personGazetteer) for s in train_corpus]\n",
        "y_train_gaz = [sent2labels(s) for s in train_corpus]\n",
        "\n",
        "X_test_gaz = [sent2featuresGaz(s, personGazetteer) for s in test_corpus]\n",
        "y_test_gaz = [sent2labels(s) for s in test_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Ik1ulsRx_V1u"
      },
      "outputs": [],
      "source": [
        "trainergaz = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train_gaz, y_train_gaz):\n",
        "    trainergaz.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZYpaWo1_V1u"
      },
      "outputs": [],
      "source": [
        "trainergaz.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 150,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmEJii-Z_V1u",
        "outputId": "4522a8d0-794d-479e-c5ea-5e5bfc5058bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.6 s, sys: 89.1 ms, total: 17.7 s\n",
            "Wall time: 17.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainergaz.train('twitter-ner-gaz.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLv8Z3Cn_V1u",
        "outputId": "1c4fb424-3353-4e9a-d7fc-08d845054325"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f34b35d36d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "taggergaz = pycrfsuite.Tagger()\n",
        "taggergaz.open('twitter-ner-gaz.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SVpg6HV_V1u",
        "outputId": "020667c3-a095-42f0-f25e-00af71a5dc99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 346 ms, sys: 949 µs, total: 347 ms\n",
            "Wall time: 349 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_pred_gaz = [taggergaz.tag(xseq) for xseq in X_test_gaz]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "aZuHRgJV_V1v"
      },
      "outputs": [],
      "source": [
        "with codecs.open('crf.out.gaz.txt', 'w') as out_file:\n",
        "    for every_sent,pred_label in zip(test_corpus, y_pred_gaz):\n",
        "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
        "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
        "            out_file.write(\"\\n\")\n",
        "        out_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh1EVs70_V1v"
      },
      "outputs": [],
      "source": [
        "true_labels, predicted_labels = conllReader(\"crf.out.gaz.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1MUMdMp_V1v",
        "outputId": "9921b46f-a780-4991-ba56-c4a282fce723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score is\n",
            "0.2762382718743181\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     company       0.75      0.10      0.18       586\n",
            "    facility       0.48      0.28      0.35       244\n",
            "     geo-loc       0.62      0.34      0.44       768\n",
            "       movie       0.14      0.04      0.06        28\n",
            " musicartist       0.12      0.01      0.01       180\n",
            "       other       0.27      0.08      0.12       535\n",
            "      person       0.34      0.41      0.38       466\n",
            "     product       0.29      0.02      0.04       216\n",
            "  sportsteam       0.00      0.00      0.00       128\n",
            "      tvshow       0.11      0.04      0.06        24\n",
            "\n",
            "   micro avg       0.45      0.20      0.28      3175\n",
            "   macro avg       0.31      0.13      0.16      3175\n",
            "weighted avg       0.45      0.20      0.25      3175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('F1 Score is')\n",
        "print( f1_score(true_labels, predicted_labels) )\n",
        "\n",
        "print('Classification report')\n",
        "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfBUC537_V1v"
      },
      "source": [
        "## Adding PoS Tag feature with the Gazetteer Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "stCgDGVl_V1w"
      },
      "outputs": [],
      "source": [
        "#Every word is represented by a set of features. CRF allows us to give any arbitrary set of features\n",
        "def word2featuresposGaz(sent, i, personGaz):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][2]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'postag=' + postag,\n",
        "        'postag[:2]=' + postag[:2],\n",
        "        'word.ispersongaz=%s' % (word.lower() in personGaz),\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][2]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            '-1:postag=' + postag1,\n",
        "            '-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][2]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            '+1:postag=' + postag1,\n",
        "            '+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "def sent2featuresposGaz(sent, personGaz, postagger):\n",
        "    tagged = postagger.tag(sent2features(sent))\n",
        "    sentNew = [word_nelabel+(pos, ) for word_nelabel,pos in zip(sent, tagged)]\n",
        "    return [word2featuresposGaz(sentNew, i, personGaz) for i in range(len(sentNew))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r__sJEWZ_V1w"
      },
      "outputs": [],
      "source": [
        "X_train_pos_gaz = [sent2featuresposGaz(s, personGazetteer, postagger) for s in train_corpus]\n",
        "y_train_pos_gaz = [sent2labels(s) for s in train_corpus]\n",
        "\n",
        "X_test_pos_gaz = [sent2featuresposGaz(s, personGazetteer,postagger) for s in test_corpus]\n",
        "y_test_pos_gaz = [sent2labels(s) for s in test_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rsalnjmY_V1w"
      },
      "outputs": [],
      "source": [
        "trainerposgaz = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train_pos_gaz, y_train_pos_gaz):\n",
        "    trainerposgaz.append(xseq, yseq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Aef3SfiE_V1w"
      },
      "outputs": [],
      "source": [
        "trainerposgaz.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 150,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXZJr5tT_V1w",
        "outputId": "4d3393b0-130a-4d7a-b111-db8e9c06110b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.4 s, sys: 103 ms, total: 21.5 s\n",
            "Wall time: 21.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainerposgaz.train('twitter-ner-pos-gaz.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nze-nL0F_V1x",
        "outputId": "4a2e7528-73a4-4101-90a2-98e7ee7be32f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f34a3f4d990>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "taggerposgaz = pycrfsuite.Tagger()\n",
        "taggerposgaz.open('twitter-ner-pos-gaz.crfsuite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwIjIuUI_V1x",
        "outputId": "7422d3f8-bf96-4d1b-f750-92080af71d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 464 ms, sys: 1.92 ms, total: 466 ms\n",
            "Wall time: 468 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "y_pred_pos_gaz = [taggerposgaz.tag(xseq) for xseq in X_test_pos_gaz]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "jU3oYAUU_V1x"
      },
      "outputs": [],
      "source": [
        "with codecs.open('crf.out.pos.gaz.txt', 'w') as out_file:\n",
        "    for every_sent,pred_label in zip(test_corpus, y_pred_pos_gaz):\n",
        "        for every_word_correct_label,predicted_label in zip(every_sent, pred_label):\n",
        "            out_file.write(every_word_correct_label[0] + \"\\t\" + every_word_correct_label[1] + \"\\t\" + predicted_label)\n",
        "            out_file.write(\"\\n\")\n",
        "        out_file.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "kNOJmWef_V1x"
      },
      "outputs": [],
      "source": [
        "true_labels, predicted_labels = conllReader(\"crf.out.pos.gaz.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypfO9TFA_V1y",
        "outputId": "f3fe77a1-bd6c-4292-f8c6-9d7ca95cd84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score is\n",
            "0.27661909989023054\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     company       0.71      0.10      0.18       586\n",
            "    facility       0.49      0.29      0.36       244\n",
            "     geo-loc       0.63      0.38      0.48       768\n",
            "       movie       0.25      0.04      0.06        28\n",
            " musicartist       0.11      0.01      0.01       180\n",
            "       other       0.22      0.07      0.10       535\n",
            "      person       0.34      0.36      0.35       466\n",
            "     product       0.27      0.02      0.03       216\n",
            "  sportsteam       0.00      0.00      0.00       128\n",
            "      tvshow       0.00      0.00      0.00        24\n",
            "\n",
            "   micro avg       0.46      0.20      0.28      3175\n",
            "   macro avg       0.30      0.13      0.16      3175\n",
            "weighted avg       0.44      0.20      0.25      3175\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('F1 Score is')\n",
        "print( f1_score(true_labels, predicted_labels) )\n",
        "\n",
        "print('Classification report')\n",
        "print( classification_report(true_labels, predicted_labels, scheme=IOB1) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YOmqKou_V1y"
      },
      "source": [
        "### This finishes the demonstration for the lab. Please go through the problem statement to complete your lab assignment.\n",
        "#### You are requested to submit it within the deadline for this assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQwHdVEH_V1y"
      },
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "interpreter": {
      "hash": "7553fb56ab976ad5aff909b9ab0e5f0d2a23e397f8c044edf0a757925c0fad4d"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}